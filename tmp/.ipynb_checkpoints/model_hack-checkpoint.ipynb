{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['make model', 'rid', 'source_url', 'id', 'dl', 'make', 'model',\n",
       "       'vehicle_type', 'car_registration_date', 'listing_price',\n",
       "       'depreciation', 'category_1', 'engine_cap', 'transmission', 'mileage',\n",
       "       'no_of_owners', 'coe', 'omv', 'arf', 'availability', 'posted_on',\n",
       "       'last_updated_on', 'company_name', 'road_tax', 'category_2',\n",
       "       'category_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "data = pd.read_csv('/Users/joelfoo/Documents/python-getting-started/data/sgcm-ads.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['make model', 'car_registration_date', 'coe', 'no_of_owners', 'mileage', 'arf', 'depreciation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "\n",
    "df['car_registration_date'] = pd.to_datetime(df['car_registration_date']) \n",
    "df['days_since_reg'] = (pd.to_datetime('today') - df['car_registration_date']).dt.days\n",
    "\n",
    "df['mileage_per_year'] = df['mileage']/(df['days_since_reg']/365)\n",
    "df['good_mileage'] = df['mileage_per_year']/1000 <= 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit dataset to top 10 cars\n",
    "top_10 = ['Honda Vezel 1.5A X',\n",
    "          'Toyota Corolla Altis 1.6A',\n",
    "          'Volkswagen Golf 1.4A TSI',\n",
    "          'Toyota Wish 1.8A', \n",
    "          'BMW 5 Series 520i',\n",
    "          'Mazda 5 2.0A Sunroof',\n",
    "          'Volkswagen Jetta 1.4A TSI',\n",
    "          'Volkswagen Scirocco 1.4A TSI',\n",
    "          'Audi A4 1.8A TFSI MU',\n",
    "          'Mercedes-Benz C-Class C180 Avantgarde'\n",
    "         ]\n",
    "\n",
    "df = df[(df['make model'].isin(top_10)) & (df['mileage'] > 0) & (df['coe'] > 0)].dropna()\n",
    "\n",
    "model_dict = {}\n",
    "for m in top_10:\n",
    "    model_dict[m] = {\"lower\": None,\n",
    "                     \"upper\": None,\n",
    "                    \"predicted\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.random.seed(123)\n",
    "\n",
    "for make_model in top_10:\n",
    "    df_m = df[df['make model'] == make_model]\n",
    "    \n",
    "    train, test = train_test_split(df_m, test_size=0.3)\n",
    "\n",
    "    coeff_list = ['coe', 'no_of_owners', 'arf', 'mileage', 'good_mileage', 'days_since_reg']\n",
    "\n",
    "    x_train = train[coeff_list]\n",
    "    y_train = train[['depreciation']]\n",
    "\n",
    "    x_test = test[coeff_list]\n",
    "    y_test= test[['depreciation']]\n",
    "    \n",
    "    #print(make_model)\n",
    "    #print(y_train)\n",
    "    \n",
    "    # GradientBoost\n",
    "    r0 = GradientBoostingRegressor(loss='quantile', alpha=0.95,\n",
    "                                   n_estimators= 10,\n",
    "                                   max_features = 'auto',\n",
    "                                   random_state=state)\n",
    "    r0.fit(x_train, y_train)\n",
    "    model_dict[make_model][\"upper\"] = pickle.dumps(r0)\n",
    "    #y_upper = r0.predict(x_test)\n",
    "\n",
    "    r0.set_params(alpha=1-0.95)\n",
    "    r0.fit(x_train,y_train)\n",
    "    model_dict[make_model][\"lower\"] = pickle.dumps(r0)\n",
    "    #y_lower = r0.predict(x_test)\n",
    "\n",
    "    r0.set_params(loss='ls')\n",
    "    r0.fit(x_train, y_train)\n",
    "    model_dict[make_model][\"predicted\"] = pickle.dumps(r0)\n",
    "    #y_pred0 = r0.predict(x_test)\n",
    "\n",
    "\n",
    "    #y_test['lower'] = y_lower\n",
    "    #y_test['pred'] = y_pred0\n",
    "    #y_test['upper'] = y_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/Users/joelfoo/Documents/python-getting-started/data/model.pkl', 'wb')\n",
    "pickle.dump(model_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-60179b589e89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import warnings\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# import pickle\n",
    "# import os\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "# np.random.seed(123)\n",
    "\n",
    "# # Read Data\n",
    "# data = pd.read_csv(dir_path + '/data/sgcm-ads.csv')\n",
    "\n",
    "# # Select necessary columns\n",
    "# df = data[['make model', 'car_registration_date', 'coe', 'no_of_owners',\n",
    "#           'mileage', 'arf', 'depreciation']]\n",
    "\n",
    "# # Feature engineering\n",
    "# df['car_registration_date'] = pd.to_datetime(df['car_registration_date'])\n",
    "# df['days_since_reg'] = (pd.to_datetime('today')\n",
    "#                         - df['car_registration_date']).dt.days\n",
    "\n",
    "# df['mileage_per_year'] = df['mileage']/(df['days_since_reg']/365)\n",
    "# df['good_mileage'] = df['mileage_per_year']/1000 <= 15\n",
    "\n",
    "# # limit dataset to top 10 cars\n",
    "# top_10 = ['Honda Vezel 1.5A X',\n",
    "#           'Toyota Corolla Altis 1.6A',\n",
    "#           'Volkswagen Golf 1.4A TSI',\n",
    "#           'Toyota Wish 1.8A',\n",
    "#           'BMW 5 Series 520i',\n",
    "#           'Mazda 5 2.0A Sunroof',\n",
    "#           'Volkswagen Jetta 1.4A TSI',\n",
    "#           'Volkswagen Scirocco 1.4A TSI',\n",
    "#           'Audi A4 1.8A TFSI MU',\n",
    "#           'Mercedes-Benz C-Class C180 Avantgarde'\n",
    "#           ]\n",
    "\n",
    "# df = df[(df['make model'].isin(top_10)) & (df['mileage'] > 0)\n",
    "#         & (df['coe'] > 0)].dropna()\n",
    "\n",
    "# # store models in dict\n",
    "# model_dict = {}\n",
    "# for m in top_10:\n",
    "#     model_dict[m] = {\"lower\": None,\n",
    "#                      \"upper\": None,\n",
    "#                      \"predicted\": None}\n",
    "\n",
    "# state = np.random.seed(123)\n",
    "# alpha = 0.95\n",
    "\n",
    "# for make_model in top_10:\n",
    "#     print(\"Generating model for \" + make_model)\n",
    "#     df_m = df[df['make model'] == make_model]\n",
    "\n",
    "#     train, test = train_test_split(df_m, test_size=0.3)\n",
    "\n",
    "#     coeff_list = ['coe', 'no_of_owners', 'arf', 'mileage', 'good_mileage',\n",
    "#                   'days_since_reg']\n",
    "\n",
    "#     x_train = train[coeff_list]\n",
    "#     y_train = train[['depreciation']]\n",
    "\n",
    "#     x_test = test[coeff_list]\n",
    "#     y_test = test[['depreciation']]\n",
    "\n",
    "#     # Train Gradient Boost Model for Upper Limit\n",
    "#     r0 = GradientBoostingRegressor(loss='quantile', alpha=alpha,\n",
    "#                                    n_estimators=10,\n",
    "#                                    max_features='auto',\n",
    "#                                    random_state=state)\n",
    "#     r0.fit(x_train, y_train)\n",
    "#     model_dict[make_model][\"upper\"] = pickle.dumps(r0)\n",
    "#     # y_upper = r0.predict(x_test)\n",
    "\n",
    "#     # Train for Lower Limit\n",
    "#     r0.set_params(alpha=1.0-alpha)\n",
    "#     r0.fit(x_train, y_train)\n",
    "#     model_dict[make_model][\"lower\"] = pickle.dumps(r0)\n",
    "#     # y_lower = r0.predict(x_test)\n",
    "\n",
    "#     # Train model for actual predictions\n",
    "#     r0.set_params(loss='ls')  # use least squares\n",
    "#     r0.fit(x_train, y_train)\n",
    "#     model_dict[make_model][\"predicted\"] = pickle.dumps(r0)\n",
    "#     # y_pred = r0.predict(x_test)\n",
    "\n",
    "# # Dump Model\n",
    "# f = open(os.path.join(dir_path + '/data/model.pkl'),\n",
    "#          'wb')\n",
    "# pickle.dump(model_dict, f)\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
