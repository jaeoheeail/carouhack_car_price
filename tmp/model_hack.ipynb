{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['make model', 'rid', 'source_url', 'id', 'dl', 'make', 'model',\n",
       "       'vehicle_type', 'car_registration_date', 'listing_price',\n",
       "       'depreciation', 'category_1', 'engine_cap', 'transmission', 'mileage',\n",
       "       'no_of_owners', 'coe', 'omv', 'arf', 'availability', 'posted_on',\n",
       "       'last_updated_on', 'company_name', 'road_tax', 'category_2',\n",
       "       'category_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "data = pd.read_csv('/Users/joelfoo/Documents/python-getting-started/data/sgcm-ads.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['make model', 'car_registration_date', 'coe', 'no_of_owners', 'mileage', 'arf', 'depreciation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "\n",
    "df['car_registration_date'] = pd.to_datetime(df['car_registration_date']) \n",
    "df['days_since_reg'] = (pd.to_datetime('today') - df['car_registration_date']).dt.days\n",
    "\n",
    "df['mileage_per_year'] = df['mileage']/(df['days_since_reg']/365)\n",
    "df['good_mileage'] = df['mileage_per_year']/1000 <= 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit dataset to top 10 cars\n",
    "top_10 = ['Honda Vezel 1.5A X',\n",
    "          'Toyota Corolla Altis 1.6A',\n",
    "          'Volkswagen Golf 1.4A TSI',\n",
    "          'Toyota Wish 1.8A', \n",
    "          'BMW 5 Series 520i',\n",
    "          'Mazda 5 2.0A Sunroof',\n",
    "          'Volkswagen Jetta 1.4A TSI',\n",
    "          'Volkswagen Scirocco 1.4A TSI',\n",
    "          'Audi A4 1.8A TFSI MU',\n",
    "          'Mercedes-Benz C-Class C180 Avantgarde'\n",
    "         ]\n",
    "\n",
    "df = df[(df['make model'].isin(top_10)) & (df['mileage'] > 0) & (df['coe'] > 0)].dropna()\n",
    "\n",
    "model_dict = {}\n",
    "for m in top_10:\n",
    "    model_dict[m] = {\"lower\": None,\n",
    "                     \"upper\": None,\n",
    "                    \"predicted\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.random.seed(123)\n",
    "\n",
    "for make_model in top_10:\n",
    "    df_m = df[df['make model'] == make_model]\n",
    "    \n",
    "    train, test = train_test_split(df_m, test_size=0.3)\n",
    "\n",
    "    coeff_list = ['coe', 'no_of_owners', 'arf', 'mileage', 'good_mileage', 'days_since_reg']\n",
    "\n",
    "    x_train = train[coeff_list]\n",
    "    y_train = train[['depreciation']]\n",
    "\n",
    "    x_test = test[coeff_list]\n",
    "    y_test= test[['depreciation']]\n",
    "    \n",
    "    #print(make_model)\n",
    "    #print(y_train)\n",
    "    \n",
    "    # GradientBoost\n",
    "    r0 = GradientBoostingRegressor(loss='quantile', alpha=0.95,\n",
    "                                   n_estimators= 10,\n",
    "                                   max_features = 'auto',\n",
    "                                   random_state=state)\n",
    "    r0.fit(x_train, y_train)\n",
    "    model_dict[make_model][\"upper\"] = pickle.dumps(r0)\n",
    "    #y_upper = r0.predict(x_test)\n",
    "\n",
    "    r0.set_params(alpha=1-0.95)\n",
    "    r0.fit(x_train,y_train)\n",
    "    model_dict[make_model][\"lower\"] = pickle.dumps(r0)\n",
    "    #y_lower = r0.predict(x_test)\n",
    "\n",
    "    r0.set_params(loss='ls')\n",
    "    r0.fit(x_train, y_train)\n",
    "    model_dict[make_model][\"predicted\"] = pickle.dumps(r0)\n",
    "    #y_pred0 = r0.predict(x_test)\n",
    "\n",
    "\n",
    "    #y_test['lower'] = y_lower\n",
    "    #y_test['pred'] = y_pred0\n",
    "    #y_test['upper'] = y_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/Users/joelfoo/Documents/python-getting-started/data/model.pkl', 'wb')\n",
    "pickle.dump(model_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
